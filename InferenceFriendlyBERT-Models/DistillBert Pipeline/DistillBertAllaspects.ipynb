{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Define the list of aspects\n",
        "aspects = [\n",
        "    'Usability', 'Performance', 'Bug', 'Security', 'Community',\n",
        "    'Compatibility', 'Documentation', 'Legal', 'Portability',\n",
        "    'OnlySentiment', 'Others'\n",
        "]\n",
        "\n",
        "# Initialize the tokenizer and model for sentiment analysis\n",
        "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Load your dataset\n",
        "file_path = '/content/BenchmarkUddinSO-ConsoliatedAspectSentiment.xls'  # Update the file path\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Filter the dataset to retain only the necessary columns\n",
        "df = data[['sent', 'ManualLabel', 'codes']]\n",
        "\n",
        "# Initialize a list to collect results\n",
        "results = []\n",
        "\n",
        "# Function to tokenize text\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(\n",
        "        texts,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "# Loop over each aspect\n",
        "for aspect in aspects:\n",
        "    print(f\"\\nProcessing aspect: {aspect}\")\n",
        "\n",
        "    # Filter the dataset for the current aspect\n",
        "    df_filtered = df[df['codes'].str.contains(aspect, case=False, na=False)].copy()\n",
        "\n",
        "    if df_filtered.empty:\n",
        "        print(f\"No data found for aspect: {aspect}\")\n",
        "        continue\n",
        "\n",
        "    # Map labels: 'p' to 1 (positive) and others to 0 (negative)\n",
        "    df_filtered['ManualLabel'] = df_filtered['ManualLabel'].apply(lambda x: 1 if x == 'p' else 0)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    train_df, test_df = train_test_split(df_filtered, test_size=0.4, random_state=42)\n",
        "\n",
        "    # Tokenize the text data\n",
        "    train_encodings = tokenize_function(train_df['sent'].tolist())\n",
        "    test_encodings = tokenize_function(test_df['sent'].tolist())\n",
        "\n",
        "    train_labels = train_df['ManualLabel'].tolist()\n",
        "    test_labels = test_df['ManualLabel'].tolist()\n",
        "\n",
        "    # Create a custom dataset class\n",
        "    class SentimentDataset(Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx]\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = SentimentDataset(train_encodings, train_labels)\n",
        "    test_dataset = SentimentDataset(test_encodings, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    num_epochs = 5\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    total_inference_time = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            logits = outputs.logits\n",
        "            preds = logits.argmax(dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            total_inference_time += inference_time\n",
        "            total_samples += input_ids.size(0)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1_micro = f1_score(true_labels, predictions, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    average_inference_time = total_inference_time / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    # Print results\n",
        "    print(f'Aspect: {aspect}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'F1 Score (Micro): {f1_micro:.4f}')\n",
        "    print(f'F1 Score (Macro): {f1_macro:.4f}')\n",
        "    print(f'F1 Score (Weighted): {f1_weighted:.4f}')\n",
        "    print(f'Total Inference Time: {total_inference_time:.6f} seconds')\n",
        "    print(f'Total Samples: {total_samples}')\n",
        "    print(f'Average Inference Time per Sample: {average_inference_time:.6f} seconds')\n",
        "\n",
        "    # Collect results\n",
        "    results.append({\n",
        "        'aspect': aspect,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'total_inference_time': total_inference_time,\n",
        "        'total_samples': total_samples,\n",
        "        'average_inference_time': average_inference_time\n",
        "    })\n",
        "\n",
        "# After processing all aspects, display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# --- Model Score Calculation --- #\n",
        "\n",
        "# Compute Average F1 Score (avg. F1)\n",
        "avg_f1 = results_df['f1_micro'].mean()\n",
        "\n",
        "# Compute Measured Average Runtime (measured avg runtime)\n",
        "measured_avg_runtime = results_df['average_inference_time'].mean()\n",
        "\n",
        "# Compute Maximum Average Runtime (max avg runtime)\n",
        "max_avg_runtime = results_df['total_inference_time'].max()\n",
        "\n",
        "# Compute the Model Score\n",
        "model_score = (avg_f1) * 0.75 + ((max_avg_runtime - measured_avg_runtime) / max_avg_runtime) * 0.25\n",
        "\n",
        "print(f\"\\nModel Score: {model_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "ssiYKaIFmTm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49bafc9-6451-47ba-c051-c862f4d1b87d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing aspect: Usability\n",
            "Epoch 1/5, Loss: 0.6611\n",
            "Epoch 2/5, Loss: 0.4158\n",
            "Epoch 3/5, Loss: 0.2008\n",
            "Epoch 4/5, Loss: 0.1013\n",
            "Epoch 5/5, Loss: 0.0978\n",
            "Aspect: Usability\n",
            "Accuracy: 0.7270\n",
            "F1 Score (Micro): 0.7270\n",
            "F1 Score (Macro): 0.6670\n",
            "F1 Score (Weighted): 0.7164\n",
            "Total Inference Time: 0.410288 seconds\n",
            "Total Samples: 575\n",
            "Average Inference Time per Sample: 0.000714 seconds\n",
            "\n",
            "Processing aspect: Performance\n",
            "Epoch 1/5, Loss: 0.8976\n",
            "Epoch 2/5, Loss: 0.4377\n",
            "Epoch 3/5, Loss: 0.2137\n",
            "Epoch 4/5, Loss: 0.0990\n",
            "Epoch 5/5, Loss: 0.0711\n",
            "Aspect: Performance\n",
            "Accuracy: 0.7000\n",
            "F1 Score (Micro): 0.7000\n",
            "F1 Score (Macro): 0.6950\n",
            "F1 Score (Weighted): 0.7062\n",
            "Total Inference Time: 0.110245 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.000787 seconds\n",
            "\n",
            "Processing aspect: Bug\n",
            "Epoch 1/5, Loss: 0.7017\n",
            "Epoch 2/5, Loss: 0.2348\n",
            "Epoch 3/5, Loss: 0.1027\n",
            "Epoch 4/5, Loss: 0.0323\n",
            "Epoch 5/5, Loss: 0.0094\n",
            "Aspect: Bug\n",
            "Accuracy: 0.8553\n",
            "F1 Score (Micro): 0.8553\n",
            "F1 Score (Macro): 0.7367\n",
            "F1 Score (Weighted): 0.8529\n",
            "Total Inference Time: 0.093516 seconds\n",
            "Total Samples: 76\n",
            "Average Inference Time per Sample: 0.001230 seconds\n",
            "\n",
            "Processing aspect: Security\n",
            "Epoch 1/5, Loss: 0.6070\n",
            "Epoch 2/5, Loss: 0.2472\n",
            "Epoch 3/5, Loss: 0.1299\n",
            "Epoch 4/5, Loss: 0.0412\n",
            "Epoch 5/5, Loss: 0.0094\n",
            "Aspect: Security\n",
            "Accuracy: 0.8636\n",
            "F1 Score (Micro): 0.8636\n",
            "F1 Score (Macro): 0.6615\n",
            "F1 Score (Weighted): 0.8280\n",
            "Total Inference Time: 0.050925 seconds\n",
            "Total Samples: 66\n",
            "Average Inference Time per Sample: 0.000772 seconds\n",
            "\n",
            "Processing aspect: Community\n",
            "Epoch 1/5, Loss: 0.9186\n",
            "Epoch 2/5, Loss: 0.1962\n",
            "Epoch 3/5, Loss: 0.0971\n",
            "Epoch 4/5, Loss: 0.0568\n",
            "Epoch 5/5, Loss: 0.0311\n",
            "Aspect: Community\n",
            "Accuracy: 0.6579\n",
            "F1 Score (Micro): 0.6579\n",
            "F1 Score (Macro): 0.5439\n",
            "F1 Score (Weighted): 0.6159\n",
            "Total Inference Time: 0.030401 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.000800 seconds\n",
            "\n",
            "Processing aspect: Compatibility\n",
            "Epoch 1/5, Loss: 0.6682\n",
            "Epoch 2/5, Loss: 0.2115\n",
            "Epoch 3/5, Loss: 0.0670\n",
            "Epoch 4/5, Loss: 0.0184\n",
            "Epoch 5/5, Loss: 0.0077\n",
            "Aspect: Compatibility\n",
            "Accuracy: 0.7368\n",
            "F1 Score (Micro): 0.7368\n",
            "F1 Score (Macro): 0.7077\n",
            "F1 Score (Weighted): 0.7417\n",
            "Total Inference Time: 0.034873 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.000918 seconds\n",
            "\n",
            "Processing aspect: Documentation\n",
            "Epoch 1/5, Loss: 0.8092\n",
            "Epoch 2/5, Loss: 0.4314\n",
            "Epoch 3/5, Loss: 0.2564\n",
            "Epoch 4/5, Loss: 0.0819\n",
            "Epoch 5/5, Loss: 0.0253\n",
            "Aspect: Documentation\n",
            "Accuracy: 0.8039\n",
            "F1 Score (Micro): 0.8039\n",
            "F1 Score (Macro): 0.7639\n",
            "F1 Score (Weighted): 0.8020\n",
            "Total Inference Time: 0.078348 seconds\n",
            "Total Samples: 102\n",
            "Average Inference Time per Sample: 0.000768 seconds\n",
            "\n",
            "Processing aspect: Legal\n",
            "Epoch 1/5, Loss: 1.1409\n",
            "Epoch 2/5, Loss: 0.2053\n",
            "Epoch 3/5, Loss: 0.1661\n",
            "Epoch 4/5, Loss: 0.1121\n",
            "Epoch 5/5, Loss: 0.0750\n",
            "Aspect: Legal\n",
            "Accuracy: 0.6500\n",
            "F1 Score (Micro): 0.6500\n",
            "F1 Score (Macro): 0.6011\n",
            "F1 Score (Weighted): 0.6151\n",
            "Total Inference Time: 0.025743 seconds\n",
            "Total Samples: 20\n",
            "Average Inference Time per Sample: 0.001287 seconds\n",
            "\n",
            "Processing aspect: Portability\n",
            "Epoch 1/5, Loss: 0.6637\n",
            "Epoch 2/5, Loss: 0.2650\n",
            "Epoch 3/5, Loss: 0.1572\n",
            "Epoch 4/5, Loss: 0.0739\n",
            "Epoch 5/5, Loss: 0.0284\n",
            "Aspect: Portability\n",
            "Accuracy: 0.7143\n",
            "F1 Score (Micro): 0.7143\n",
            "F1 Score (Macro): 0.6889\n",
            "F1 Score (Weighted): 0.7270\n",
            "Total Inference Time: 0.023248 seconds\n",
            "Total Samples: 28\n",
            "Average Inference Time per Sample: 0.000830 seconds\n",
            "\n",
            "Processing aspect: OnlySentiment\n",
            "Epoch 1/5, Loss: 0.7876\n",
            "Epoch 2/5, Loss: 0.4561\n",
            "Epoch 3/5, Loss: 0.2298\n",
            "Epoch 4/5, Loss: 0.0813\n",
            "Epoch 5/5, Loss: 0.0561\n",
            "Aspect: OnlySentiment\n",
            "Accuracy: 0.7071\n",
            "F1 Score (Micro): 0.7071\n",
            "F1 Score (Macro): 0.6852\n",
            "F1 Score (Weighted): 0.7030\n",
            "Total Inference Time: 0.101337 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.000724 seconds\n",
            "\n",
            "Processing aspect: Others\n",
            "Epoch 1/5, Loss: 0.3795\n",
            "Epoch 2/5, Loss: 0.2943\n",
            "Epoch 3/5, Loss: 0.1895\n",
            "Epoch 4/5, Loss: 0.1314\n",
            "Epoch 5/5, Loss: 0.0949\n",
            "Aspect: Others\n",
            "Accuracy: 0.8765\n",
            "F1 Score (Micro): 0.8765\n",
            "F1 Score (Macro): 0.5293\n",
            "F1 Score (Weighted): 0.8420\n",
            "Total Inference Time: 0.496834 seconds\n",
            "Total Samples: 680\n",
            "Average Inference Time per Sample: 0.000731 seconds\n",
            "\n",
            "Final Results:\n",
            "           aspect  accuracy  f1_micro  f1_macro  f1_weighted  \\\n",
            "0       Usability  0.726957  0.726957  0.666991     0.716389   \n",
            "1     Performance  0.700000  0.700000  0.694957     0.706163   \n",
            "2             Bug  0.855263  0.855263  0.736693     0.852938   \n",
            "3        Security  0.863636  0.863636  0.661538     0.827972   \n",
            "4       Community  0.657895  0.657895  0.543860     0.615882   \n",
            "5   Compatibility  0.736842  0.736842  0.707692     0.741700   \n",
            "6   Documentation  0.803922  0.803922  0.763889     0.802015   \n",
            "7           Legal  0.650000  0.650000  0.601140     0.615100   \n",
            "8     Portability  0.714286  0.714286  0.688889     0.726984   \n",
            "9   OnlySentiment  0.707143  0.707143  0.685152     0.702982   \n",
            "10         Others  0.876471  0.876471  0.529272     0.841989   \n",
            "\n",
            "    total_inference_time  total_samples  average_inference_time  \n",
            "0               0.410288            575                0.000714  \n",
            "1               0.110245            140                0.000787  \n",
            "2               0.093516             76                0.001230  \n",
            "3               0.050925             66                0.000772  \n",
            "4               0.030401             38                0.000800  \n",
            "5               0.034873             38                0.000918  \n",
            "6               0.078348            102                0.000768  \n",
            "7               0.025743             20                0.001287  \n",
            "8               0.023248             28                0.000830  \n",
            "9               0.101337            140                0.000724  \n",
            "10              0.496834            680                0.000731  \n",
            "\n",
            "Model Score: 0.8150\n"
          ]
        }
      ]
    }
  ]
}