{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "221d3c411f3243febfad59c3f9423a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_500fb77886cf4250a601003f4df8ebd0",
              "IPY_MODEL_19661776675b46e88f01f4b948ae2c2b",
              "IPY_MODEL_9b6cf239c2f149c2b3206c8667e6f236"
            ],
            "layout": "IPY_MODEL_c1b2b9b17a3149d28211eb21387015a3"
          }
        },
        "500fb77886cf4250a601003f4df8ebd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565021cb767843f6b5f40b1910a14770",
            "placeholder": "​",
            "style": "IPY_MODEL_cb6bba86f4984e79ad48efc3408de284",
            "value": "vocab.txt: 100%"
          }
        },
        "19661776675b46e88f01f4b948ae2c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e54113f40fd641e08f668f81427256aa",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41915dfb327d4b0e8e1319cbc10d4e29",
            "value": 231508
          }
        },
        "9b6cf239c2f149c2b3206c8667e6f236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac901b0d4f7145bca3a8fa630ee3dbf9",
            "placeholder": "​",
            "style": "IPY_MODEL_919c93584b1a4fc384cadbc7e2b181a3",
            "value": " 232k/232k [00:00&lt;00:00, 6.26MB/s]"
          }
        },
        "c1b2b9b17a3149d28211eb21387015a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565021cb767843f6b5f40b1910a14770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb6bba86f4984e79ad48efc3408de284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e54113f40fd641e08f668f81427256aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41915dfb327d4b0e8e1319cbc10d4e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac901b0d4f7145bca3a8fa630ee3dbf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919c93584b1a4fc384cadbc7e2b181a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d50a0b6bf78409c917b0317118a7f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e2766009e5c4e6ca5af3ceb483f436e",
              "IPY_MODEL_20a5304de696493da953d8def31f230b",
              "IPY_MODEL_7c0966ff11b342cc890623b13b3ab17d"
            ],
            "layout": "IPY_MODEL_8b09d35a76e6429794e58e4ff445c999"
          }
        },
        "2e2766009e5c4e6ca5af3ceb483f436e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ebe427970d3431c9f056deefe28fb62",
            "placeholder": "​",
            "style": "IPY_MODEL_4a9e00a1c3c54a20b2e3de5bb1d37373",
            "value": "config.json: 100%"
          }
        },
        "20a5304de696493da953d8def31f230b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7baf7bf0c9e745f28f1807d900374f1f",
            "max": 409,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91365f0f2e1c4bbf82ceffd6c8563463",
            "value": 409
          }
        },
        "7c0966ff11b342cc890623b13b3ab17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bad28276687459394f9c42e884cc2f6",
            "placeholder": "​",
            "style": "IPY_MODEL_8748e1bb1c524f8b9b53128502373141",
            "value": " 409/409 [00:00&lt;00:00, 25.1kB/s]"
          }
        },
        "8b09d35a76e6429794e58e4ff445c999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ebe427970d3431c9f056deefe28fb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a9e00a1c3c54a20b2e3de5bb1d37373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7baf7bf0c9e745f28f1807d900374f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91365f0f2e1c4bbf82ceffd6c8563463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bad28276687459394f9c42e884cc2f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8748e1bb1c524f8b9b53128502373141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44bbd58e433c4767ba99fd7883723db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a345c6cad74d424e8100660c4d612adb",
              "IPY_MODEL_25db1f1367f14b7089520168baf93d81",
              "IPY_MODEL_f710a8aea9a742669000c84e9ca855c6"
            ],
            "layout": "IPY_MODEL_b14c69dac3224b5186da559c32e2a4c3"
          }
        },
        "a345c6cad74d424e8100660c4d612adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5010e21d8ae4c7ab4a697cb20567814",
            "placeholder": "​",
            "style": "IPY_MODEL_0c5cb64d3a364646b9be6be4d3996de4",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "25db1f1367f14b7089520168baf93d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deff69f90ed448c19158442a5ab3845e",
            "max": 62747391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ead56e3dd5004cca9eb83a85992ced1f",
            "value": 62747391
          }
        },
        "f710a8aea9a742669000c84e9ca855c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c5be703cf1494895d1a0824c04d587",
            "placeholder": "​",
            "style": "IPY_MODEL_5eb747205781477dbf780a3b51f2374f",
            "value": " 62.7M/62.7M [00:02&lt;00:00, 45.4MB/s]"
          }
        },
        "b14c69dac3224b5186da559c32e2a4c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5010e21d8ae4c7ab4a697cb20567814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5cb64d3a364646b9be6be4d3996de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deff69f90ed448c19158442a5ab3845e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead56e3dd5004cca9eb83a85992ced1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65c5be703cf1494895d1a0824c04d587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eb747205781477dbf780a3b51f2374f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a8cb2d586284ebe82d3ee6ee5a82626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51c0a6b4e16c4ed7843640c66ec126ee",
              "IPY_MODEL_66c823828586421faebab29ae48e22f8",
              "IPY_MODEL_ad91860ea2754f77a9d7facec2079b4b"
            ],
            "layout": "IPY_MODEL_9a35af8a013a497c85678d4fa5e79a3c"
          }
        },
        "51c0a6b4e16c4ed7843640c66ec126ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c344cae90c004f29b87b1ae75969982b",
            "placeholder": "​",
            "style": "IPY_MODEL_ceb338cfe4474a95941a868286354c7f",
            "value": "vocab.json: 100%"
          }
        },
        "66c823828586421faebab29ae48e22f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7536aad74534a54a5fd6240830fe595",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59fed2e517394c1eb5d697c75b83e193",
            "value": 898823
          }
        },
        "ad91860ea2754f77a9d7facec2079b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e006879344a440da0fe8b70f3d8ed53",
            "placeholder": "​",
            "style": "IPY_MODEL_7d6c547fed374fdc9c95a3bd6f699193",
            "value": " 899k/899k [00:00&lt;00:00, 3.50MB/s]"
          }
        },
        "9a35af8a013a497c85678d4fa5e79a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c344cae90c004f29b87b1ae75969982b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb338cfe4474a95941a868286354c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7536aad74534a54a5fd6240830fe595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59fed2e517394c1eb5d697c75b83e193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e006879344a440da0fe8b70f3d8ed53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6c547fed374fdc9c95a3bd6f699193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b129832d2b8848dbb1299e5709dbf40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2404ed4b6dd490580de79420e7b2a66",
              "IPY_MODEL_231364ce4bab4c7bb6cb824983af2caa",
              "IPY_MODEL_01767d020b23433fb982491dd49ecb00"
            ],
            "layout": "IPY_MODEL_5d5c12b51513458cbb12f315760eabb1"
          }
        },
        "b2404ed4b6dd490580de79420e7b2a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7897f868a2ac44c28ebfa2d8553b2e13",
            "placeholder": "​",
            "style": "IPY_MODEL_be574c99ebb346d4b2f73568c0225a7b",
            "value": "merges.txt: 100%"
          }
        },
        "231364ce4bab4c7bb6cb824983af2caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3c63b807e81425fb48cbcef4afbf89c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2849510b6bc4bbda8110f59aa3e56f3",
            "value": 456318
          }
        },
        "01767d020b23433fb982491dd49ecb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7796098294140e5a3fbd2d5661733ea",
            "placeholder": "​",
            "style": "IPY_MODEL_3cb212392a884df8b1540e513a9fb2bc",
            "value": " 456k/456k [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "5d5c12b51513458cbb12f315760eabb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7897f868a2ac44c28ebfa2d8553b2e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be574c99ebb346d4b2f73568c0225a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3c63b807e81425fb48cbcef4afbf89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2849510b6bc4bbda8110f59aa3e56f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7796098294140e5a3fbd2d5661733ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb212392a884df8b1540e513a9fb2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "358a75d0732d403d9535f855f58f737d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7822d87e846e42a0b4e3395f4de29e52",
              "IPY_MODEL_032804685f6a47f4854bf938fa0148a3",
              "IPY_MODEL_69fdc1eceda343209f893ba4cfdfa45c"
            ],
            "layout": "IPY_MODEL_e7e6b7282eb44ab1a1aa06f8ed6cad43"
          }
        },
        "7822d87e846e42a0b4e3395f4de29e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29b899f207434a649c32c83f870cef2b",
            "placeholder": "​",
            "style": "IPY_MODEL_d2ff471a42604168ae1135d2bd948fac",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "032804685f6a47f4854bf938fa0148a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d00790f52153409287b644cd652f6cad",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27611a0011304f229493bb336437cb8d",
            "value": 25
          }
        },
        "69fdc1eceda343209f893ba4cfdfa45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865d0b02bbb34186a8da13005dc6a03f",
            "placeholder": "​",
            "style": "IPY_MODEL_04d614cff9f74e3a872cde20ea43b1b8",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.35kB/s]"
          }
        },
        "e7e6b7282eb44ab1a1aa06f8ed6cad43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b899f207434a649c32c83f870cef2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ff471a42604168ae1135d2bd948fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d00790f52153409287b644cd652f6cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27611a0011304f229493bb336437cb8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "865d0b02bbb34186a8da13005dc6a03f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d614cff9f74e3a872cde20ea43b1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49686b7deee24f6fa3306a354b669edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdf0d9e67d22437c91e00739dac37716",
              "IPY_MODEL_949543220b6841f29e92469a965eed7f",
              "IPY_MODEL_f93dd733f64b4e4c99336fe83697cc9d"
            ],
            "layout": "IPY_MODEL_f36cb60a34c34fad99bd758b7b3e50d4"
          }
        },
        "bdf0d9e67d22437c91e00739dac37716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afb8733b5cc944e2bd0565c55d6f945e",
            "placeholder": "​",
            "style": "IPY_MODEL_5946c4c546304987a44d36de36489965",
            "value": "config.json: 100%"
          }
        },
        "949543220b6841f29e92469a965eed7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9938292b03d434080814889e21bf50e",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0047eff84369450fae2b9e51d4470e39",
            "value": 482
          }
        },
        "f93dd733f64b4e4c99336fe83697cc9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91da51ada0414a0bb493884cef0626fc",
            "placeholder": "​",
            "style": "IPY_MODEL_253a98d1c08b4a1d93ff9f6f865978bf",
            "value": " 482/482 [00:00&lt;00:00, 25.3kB/s]"
          }
        },
        "f36cb60a34c34fad99bd758b7b3e50d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb8733b5cc944e2bd0565c55d6f945e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5946c4c546304987a44d36de36489965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9938292b03d434080814889e21bf50e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0047eff84369450fae2b9e51d4470e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91da51ada0414a0bb493884cef0626fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253a98d1c08b4a1d93ff9f6f865978bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b04ac51ec0d24c33a833fdf017dd9fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0b692cc587a4d8aae358e5fdc232271",
              "IPY_MODEL_1847ffc6a2884d91958fc863fe130cf8",
              "IPY_MODEL_a35ac1ce1556491f8790f71e45295c47"
            ],
            "layout": "IPY_MODEL_853ff37c402f4fb4bc902ba1c96fae13"
          }
        },
        "a0b692cc587a4d8aae358e5fdc232271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eafac7c5a9e24dd3b876ef0fd0a63d69",
            "placeholder": "​",
            "style": "IPY_MODEL_45f93f2e44a741e29e8fcd38a1eb8c0c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1847ffc6a2884d91958fc863fe130cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_986588776d2d4502b02fb4c4e9b99f83",
            "max": 1425941629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaa78cfcf2a94ea8aa119a50225c17b5",
            "value": 1425941629
          }
        },
        "a35ac1ce1556491f8790f71e45295c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367629cd71114f71821829cb2cfa31f0",
            "placeholder": "​",
            "style": "IPY_MODEL_2cbf39a147774d60bd5d539fe093dd5b",
            "value": " 1.43G/1.43G [00:22&lt;00:00, 80.6MB/s]"
          }
        },
        "853ff37c402f4fb4bc902ba1c96fae13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eafac7c5a9e24dd3b876ef0fd0a63d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f93f2e44a741e29e8fcd38a1eb8c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "986588776d2d4502b02fb4c4e9b99f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaa78cfcf2a94ea8aa119a50225c17b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "367629cd71114f71821829cb2cfa31f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbf39a147774d60bd5d539fe093dd5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFd7E35lymr0",
        "outputId": "49205e32-6ebb-478a-bbb4-5b6f8b05db70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing aspect: Usability\n",
            "Epoch 1/5, Loss: 0.6255\n",
            "Epoch 2/5, Loss: 0.6136\n",
            "Epoch 3/5, Loss: 0.5630\n",
            "Epoch 4/5, Loss: 0.4950\n",
            "Epoch 5/5, Loss: 0.3917\n",
            "Aspect: Usability\n",
            "Accuracy: 0.6730\n",
            "F1 Score (Micro): 0.6730\n",
            "F1 Score (Macro): 0.5797\n",
            "F1 Score (Weighted): 0.6489\n",
            "Total Inference Time: 0.040590 seconds\n",
            "Total Samples: 575\n",
            "Average Inference Time per Sample: 0.000071 seconds\n",
            "\n",
            "Processing aspect: Performance\n",
            "Epoch 1/5, Loss: 0.6809\n",
            "Epoch 2/5, Loss: 0.6677\n",
            "Epoch 3/5, Loss: 0.6543\n",
            "Epoch 4/5, Loss: 0.5946\n",
            "Epoch 5/5, Loss: 0.5176\n",
            "Aspect: Performance\n",
            "Accuracy: 0.6286\n",
            "F1 Score (Micro): 0.6286\n",
            "F1 Score (Macro): 0.5304\n",
            "F1 Score (Weighted): 0.5918\n",
            "Total Inference Time: 0.007365 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.000053 seconds\n",
            "\n",
            "Processing aspect: Bug\n",
            "Epoch 1/5, Loss: 0.4758\n",
            "Epoch 2/5, Loss: 0.4239\n",
            "Epoch 3/5, Loss: 0.4182\n",
            "Epoch 4/5, Loss: 0.4146\n",
            "Epoch 5/5, Loss: 0.4049\n",
            "Aspect: Bug\n",
            "Accuracy: 0.8289\n",
            "F1 Score (Micro): 0.8289\n",
            "F1 Score (Macro): 0.4532\n",
            "F1 Score (Weighted): 0.7514\n",
            "Total Inference Time: 0.004533 seconds\n",
            "Total Samples: 76\n",
            "Average Inference Time per Sample: 0.000060 seconds\n",
            "\n",
            "Processing aspect: Security\n",
            "Epoch 1/5, Loss: 0.5287\n",
            "Epoch 2/5, Loss: 0.4576\n",
            "Epoch 3/5, Loss: 0.4403\n",
            "Epoch 4/5, Loss: 0.4446\n",
            "Epoch 5/5, Loss: 0.4324\n",
            "Aspect: Security\n",
            "Accuracy: 0.8182\n",
            "F1 Score (Micro): 0.8182\n",
            "F1 Score (Macro): 0.4500\n",
            "F1 Score (Weighted): 0.7364\n",
            "Total Inference Time: 0.003105 seconds\n",
            "Total Samples: 66\n",
            "Average Inference Time per Sample: 0.000047 seconds\n",
            "\n",
            "Processing aspect: Community\n",
            "Epoch 1/5, Loss: 0.5642\n",
            "Epoch 2/5, Loss: 0.5613\n",
            "Epoch 3/5, Loss: 0.5627\n",
            "Epoch 4/5, Loss: 0.5444\n",
            "Epoch 5/5, Loss: 0.5321\n",
            "Aspect: Community\n",
            "Accuracy: 0.6579\n",
            "F1 Score (Micro): 0.6579\n",
            "F1 Score (Macro): 0.3968\n",
            "F1 Score (Weighted): 0.5221\n",
            "Total Inference Time: 0.001900 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.000050 seconds\n",
            "\n",
            "Processing aspect: Compatibility\n",
            "Epoch 1/5, Loss: 0.7344\n",
            "Epoch 2/5, Loss: 0.6868\n",
            "Epoch 3/5, Loss: 0.7007\n",
            "Epoch 4/5, Loss: 0.6684\n",
            "Epoch 5/5, Loss: 0.6611\n",
            "Aspect: Compatibility\n",
            "Accuracy: 0.6842\n",
            "F1 Score (Micro): 0.6842\n",
            "F1 Score (Macro): 0.4062\n",
            "F1 Score (Weighted): 0.5559\n",
            "Total Inference Time: 0.001895 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.000050 seconds\n",
            "\n",
            "Processing aspect: Documentation\n",
            "Epoch 1/5, Loss: 0.6016\n",
            "Epoch 2/5, Loss: 0.5989\n",
            "Epoch 3/5, Loss: 0.5759\n",
            "Epoch 4/5, Loss: 0.5732\n",
            "Epoch 5/5, Loss: 0.5441\n",
            "Aspect: Documentation\n",
            "Accuracy: 0.6863\n",
            "F1 Score (Micro): 0.6863\n",
            "F1 Score (Macro): 0.4603\n",
            "F1 Score (Weighted): 0.5973\n",
            "Total Inference Time: 0.004222 seconds\n",
            "Total Samples: 102\n",
            "Average Inference Time per Sample: 0.000041 seconds\n",
            "\n",
            "Processing aspect: Legal\n",
            "Epoch 1/5, Loss: 0.6208\n",
            "Epoch 2/5, Loss: 0.6243\n",
            "Epoch 3/5, Loss: 0.6322\n",
            "Epoch 4/5, Loss: 0.6217\n",
            "Epoch 5/5, Loss: 0.5928\n",
            "Aspect: Legal\n",
            "Accuracy: 0.5500\n",
            "F1 Score (Micro): 0.5500\n",
            "F1 Score (Macro): 0.3548\n",
            "F1 Score (Weighted): 0.3903\n",
            "Total Inference Time: 0.001114 seconds\n",
            "Total Samples: 20\n",
            "Average Inference Time per Sample: 0.000056 seconds\n",
            "\n",
            "Processing aspect: Portability\n",
            "Epoch 1/5, Loss: 0.6554\n",
            "Epoch 2/5, Loss: 0.6014\n",
            "Epoch 3/5, Loss: 0.7015\n",
            "Epoch 4/5, Loss: 0.5602\n",
            "Epoch 5/5, Loss: 0.5585\n",
            "Aspect: Portability\n",
            "Accuracy: 0.7143\n",
            "F1 Score (Micro): 0.7143\n",
            "F1 Score (Macro): 0.4167\n",
            "F1 Score (Weighted): 0.5952\n",
            "Total Inference Time: 0.001373 seconds\n",
            "Total Samples: 28\n",
            "Average Inference Time per Sample: 0.000049 seconds\n",
            "\n",
            "Processing aspect: OnlySentiment\n",
            "Epoch 1/5, Loss: 0.7208\n",
            "Epoch 2/5, Loss: 0.6924\n",
            "Epoch 3/5, Loss: 0.6549\n",
            "Epoch 4/5, Loss: 0.6341\n",
            "Epoch 5/5, Loss: 0.5868\n",
            "Aspect: OnlySentiment\n",
            "Accuracy: 0.6286\n",
            "F1 Score (Micro): 0.6286\n",
            "F1 Score (Macro): 0.5450\n",
            "F1 Score (Weighted): 0.5868\n",
            "Total Inference Time: 0.005708 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.000041 seconds\n",
            "\n",
            "Processing aspect: Others\n",
            "Epoch 1/5, Loss: 0.3555\n",
            "Epoch 2/5, Loss: 0.3362\n",
            "Epoch 3/5, Loss: 0.3364\n",
            "Epoch 4/5, Loss: 0.3134\n",
            "Epoch 5/5, Loss: 0.2835\n",
            "Aspect: Others\n",
            "Accuracy: 0.8868\n",
            "F1 Score (Micro): 0.8868\n",
            "F1 Score (Macro): 0.4700\n",
            "F1 Score (Weighted): 0.8335\n",
            "Total Inference Time: 0.028179 seconds\n",
            "Total Samples: 680\n",
            "Average Inference Time per Sample: 0.000041 seconds\n",
            "\n",
            "Final Results:\n",
            "           aspect  accuracy  f1_micro  f1_macro  f1_weighted  \\\n",
            "0       Usability  0.673043  0.673043  0.579678     0.648927   \n",
            "1     Performance  0.628571  0.628571  0.530444     0.591774   \n",
            "2             Bug  0.828947  0.828947  0.453237     0.751420   \n",
            "3        Security  0.818182  0.818182  0.450000     0.736364   \n",
            "4       Community  0.657895  0.657895  0.396825     0.522139   \n",
            "5   Compatibility  0.684211  0.684211  0.406250     0.555921   \n",
            "6   Documentation  0.686275  0.686275  0.460317     0.597261   \n",
            "7           Legal  0.550000  0.550000  0.354839     0.390323   \n",
            "8     Portability  0.714286  0.714286  0.416667     0.595238   \n",
            "9   OnlySentiment  0.628571  0.628571  0.545000     0.586786   \n",
            "10         Others  0.886765  0.886765  0.469992     0.833545   \n",
            "\n",
            "    total_inference_time  total_samples  average_inference_time  \n",
            "0               0.040590            575                0.000071  \n",
            "1               0.007365            140                0.000053  \n",
            "2               0.004533             76                0.000060  \n",
            "3               0.003105             66                0.000047  \n",
            "4               0.001900             38                0.000050  \n",
            "5               0.001895             38                0.000050  \n",
            "6               0.004222            102                0.000041  \n",
            "7               0.001114             20                0.000056  \n",
            "8               0.001373             28                0.000049  \n",
            "9               0.005708            140                0.000041  \n",
            "10              0.028179            680                0.000041  \n",
            "\n",
            "Model Score: 0.7786\n"
          ]
        }
      ],
      "source": [
        "# Bert base uncased\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Define the list of aspects\n",
        "aspects = [\n",
        "    'Usability', 'Performance', 'Bug', 'Security', 'Community',\n",
        "    'Compatibility', 'Documentation', 'Legal', 'Portability',\n",
        "    'OnlySentiment', 'Others'\n",
        "]\n",
        "\n",
        "# Define the attention module using PyTorch's scaled_dot_product_attention\n",
        "class ScaledDotProductAttentionModule(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(ScaledDotProductAttentionModule, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.embed_dim = embed_dim\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        assert self.head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n",
        "        self.qkv_proj = nn.Linear(embed_dim, embed_dim * 3)\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "        qkv = self.qkv_proj(x)\n",
        "        qkv = qkv.view(batch_size, seq_length, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv.unbind(0)\n",
        "\n",
        "        attn_output = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0.1, is_causal=False)\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_length, self.embed_dim)\n",
        "        output = self.out_proj(attn_output)\n",
        "        return output\n",
        "\n",
        "# Define the model\n",
        "class CustomSequenceClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_heads, num_labels=2):\n",
        "        super(CustomSequenceClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.attention = ScaledDotProductAttentionModule(embedding_dim, num_heads)\n",
        "        self.classifier = nn.Linear(embedding_dim, num_labels)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.embedding(input_ids)\n",
        "        attention_output = self.attention(x)\n",
        "        pooled_output = attention_output.mean(dim=1)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# File path to your dataset (update this path)\n",
        "file_path = '/content/BenchmarkUddinSO-ConsoliatedAspectSentiment.xls'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(file_path)\n",
        "df = data[['sent', 'ManualLabel', 'codes']]\n",
        "\n",
        "# Initialize a list to collect results\n",
        "results = []\n",
        "\n",
        "# Loop over each aspect\n",
        "for aspect in aspects:\n",
        "    print(f\"\\nProcessing aspect: {aspect}\")\n",
        "    # Filter the dataset for the current aspect\n",
        "    df_filtered = df[df['codes'].str.contains(aspect, case=False, na=False)].copy()\n",
        "\n",
        "    # Check if the filtered dataset is empty\n",
        "    if df_filtered.empty:\n",
        "        print(f\"No data found for aspect: {aspect}\")\n",
        "        continue\n",
        "\n",
        "    # Map labels: 'p' to 1 and others to 0\n",
        "    df_filtered['ManualLabel'] = df_filtered['ManualLabel'].apply(lambda x: 1 if x == 'p' else 0)\n",
        "\n",
        "    # Split the dataset\n",
        "    train_df, test_df = train_test_split(df_filtered, test_size=0.4, random_state=42)\n",
        "\n",
        "    # Tokenize the text data\n",
        "    def tokenize_function(texts):\n",
        "        return tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "    train_texts = train_df['sent'].tolist()\n",
        "    train_labels = train_df['ManualLabel'].tolist()\n",
        "    test_texts = test_df['sent'].tolist()\n",
        "    test_labels = test_df['ManualLabel'].tolist()\n",
        "\n",
        "    train_encodings = tokenize_function(train_texts)\n",
        "    test_encodings = tokenize_function(test_texts)\n",
        "\n",
        "    # Create a custom dataset class\n",
        "    class SentimentDataset(Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = {key: val.clone().detach() for key, val in encodings.items()}\n",
        "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx]\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = SentimentDataset(train_encodings, train_labels)\n",
        "    test_dataset = SentimentDataset(test_encodings, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    vocab_size = tokenizer.vocab_size\n",
        "    embedding_dim = 768\n",
        "    num_heads = 12\n",
        "    num_labels = 2\n",
        "\n",
        "    model = CustomSequenceClassifier(\n",
        "        vocab_size=vocab_size,\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_heads=num_heads,\n",
        "        num_labels=num_labels\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    num_epochs = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(input_ids)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    total_inference_time = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "            logits = model(input_ids)\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            preds = logits.argmax(dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            total_inference_time += inference_time\n",
        "            total_samples += input_ids.size(0)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1_micro = f1_score(true_labels, predictions, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    average_inference_time = total_inference_time / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    # Print results\n",
        "    print(f'Aspect: {aspect}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'F1 Score (Micro): {f1_micro:.4f}')\n",
        "    print(f'F1 Score (Macro): {f1_macro:.4f}')\n",
        "    print(f'F1 Score (Weighted): {f1_weighted:.4f}')\n",
        "    print(f'Total Inference Time: {total_inference_time:.6f} seconds')\n",
        "    print(f'Total Samples: {total_samples}')\n",
        "    print(f'Average Inference Time per Sample: {average_inference_time:.6f} seconds')\n",
        "\n",
        "    # Collect results\n",
        "    results.append({\n",
        "        'aspect': aspect,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'total_inference_time': total_inference_time,\n",
        "        'total_samples': total_samples,\n",
        "        'average_inference_time': average_inference_time\n",
        "    })\n",
        "\n",
        "# After processing all aspects, display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# --- Model Score Calculation --- #\n",
        "\n",
        "# Compute Average F1 Score (avg. F1)\n",
        "avg_f1 = results_df['f1_micro'].mean()\n",
        "\n",
        "# Compute Measured Average Runtime (measured avg runtime)\n",
        "measured_avg_runtime = results_df['average_inference_time'].mean()\n",
        "\n",
        "# Compute Maximum Average Runtime (max avg runtime)\n",
        "max_avg_runtime = results_df['total_inference_time'].max()\n",
        "\n",
        "# Compute the Model Score\n",
        "model_score = (avg_f1) * 0.75 + ((max_avg_runtime - measured_avg_runtime) / max_avg_runtime) * 0.25\n",
        "\n",
        "print(f\"\\nModel Score: {model_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiny Bert\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Define the list of aspects\n",
        "aspects = [\n",
        "    'Usability', 'Performance', 'Bug', 'Security', 'Community',\n",
        "    'Compatibility', 'Documentation', 'Legal', 'Portability',\n",
        "    'OnlySentiment', 'Others'\n",
        "]\n",
        "\n",
        "# Initialize the tokenizer (TinyBERT tokenizer)\n",
        "tokenizer = BertTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
        "\n",
        "# File path to your dataset (update this path)\n",
        "file_path = '/content/BenchmarkUddinSO-ConsoliatedAspectSentiment.xls'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(file_path)\n",
        "df = data[['sent', 'ManualLabel', 'codes']]\n",
        "\n",
        "# Initialize a list to collect results\n",
        "results = []\n",
        "\n",
        "# Loop over each aspect\n",
        "for aspect in aspects:\n",
        "    print(f\"\\nProcessing aspect: {aspect}\")\n",
        "    # Filter the dataset for the current aspect\n",
        "    df_filtered = df[df['codes'].str.contains(aspect, case=False, na=False)].copy()\n",
        "\n",
        "    # Check if the filtered dataset is empty\n",
        "    if df_filtered.empty:\n",
        "        print(f\"No data found for aspect: {aspect}\")\n",
        "        continue\n",
        "\n",
        "    # Map labels: 'p' to 1 and others to 0\n",
        "    df_filtered['ManualLabel'] = df_filtered['ManualLabel'].apply(lambda x: 1 if x == 'p' else 0)\n",
        "\n",
        "    # Split the dataset\n",
        "    train_df, test_df = train_test_split(df_filtered, test_size=0.4, random_state=42)\n",
        "\n",
        "    # Tokenize the text data\n",
        "    def tokenize_function(texts):\n",
        "        return tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "    train_texts = train_df['sent'].tolist()\n",
        "    train_labels = train_df['ManualLabel'].tolist()\n",
        "    test_texts = test_df['sent'].tolist()\n",
        "    test_labels = test_df['ManualLabel'].tolist()\n",
        "\n",
        "    train_encodings = tokenize_function(train_texts)\n",
        "    test_encodings = tokenize_function(test_texts)\n",
        "\n",
        "    # Create a custom dataset class\n",
        "    class SentimentDataset(Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = {key: val.clone().detach() for key, val in encodings.items()}\n",
        "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx]\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = SentimentDataset(train_encodings, train_labels)\n",
        "    test_dataset = SentimentDataset(test_encodings, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # Initialize the TinyBERT model for sequence classification\n",
        "    model = BertForSequenceClassification.from_pretrained('huawei-noah/TinyBERT_General_4L_312D', num_labels=2)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    num_epochs = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    total_inference_time = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            total_inference_time += inference_time\n",
        "            total_samples += input_ids.size(0)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1_micro = f1_score(true_labels, predictions, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    average_inference_time = total_inference_time / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    # Print results\n",
        "    print(f'Aspect: {aspect}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'F1 Score (Micro): {f1_micro:.4f}')\n",
        "    print(f'F1 Score (Macro): {f1_macro:.4f}')\n",
        "    print(f'F1 Score (Weighted): {f1_weighted:.4f}')\n",
        "    print(f'Total Inference Time: {total_inference_time:.6f} seconds')\n",
        "    print(f'Total Samples: {total_samples}')\n",
        "    print(f'Average Inference Time per Sample: {average_inference_time:.6f} seconds')\n",
        "\n",
        "    # Collect results\n",
        "    results.append({\n",
        "        'aspect': aspect,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'total_inference_time': total_inference_time,\n",
        "        'total_samples': total_samples,\n",
        "        'average_inference_time': average_inference_time\n",
        "    })\n",
        "\n",
        "# After processing all aspects, display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# --- Model Score Calculation --- #\n",
        "\n",
        "# Compute Average F1 Score (avg. F1)\n",
        "avg_f1 = results_df['f1_micro'].mean()\n",
        "\n",
        "# Compute Measured Average Runtime (measured avg runtime)\n",
        "measured_avg_runtime = results_df['average_inference_time'].mean()\n",
        "\n",
        "# Compute Maximum Average Runtime (max avg runtime)\n",
        "max_avg_runtime = results_df['total_inference_time'].max()\n",
        "\n",
        "# Compute the Model Score\n",
        "model_score = (avg_f1) * 0.75 + ((max_avg_runtime - measured_avg_runtime) / max_avg_runtime) * 0.25\n",
        "\n",
        "print(f\"\\nModel Score: {model_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "221d3c411f3243febfad59c3f9423a11",
            "500fb77886cf4250a601003f4df8ebd0",
            "19661776675b46e88f01f4b948ae2c2b",
            "9b6cf239c2f149c2b3206c8667e6f236",
            "c1b2b9b17a3149d28211eb21387015a3",
            "565021cb767843f6b5f40b1910a14770",
            "cb6bba86f4984e79ad48efc3408de284",
            "e54113f40fd641e08f668f81427256aa",
            "41915dfb327d4b0e8e1319cbc10d4e29",
            "ac901b0d4f7145bca3a8fa630ee3dbf9",
            "919c93584b1a4fc384cadbc7e2b181a3",
            "4d50a0b6bf78409c917b0317118a7f01",
            "2e2766009e5c4e6ca5af3ceb483f436e",
            "20a5304de696493da953d8def31f230b",
            "7c0966ff11b342cc890623b13b3ab17d",
            "8b09d35a76e6429794e58e4ff445c999",
            "0ebe427970d3431c9f056deefe28fb62",
            "4a9e00a1c3c54a20b2e3de5bb1d37373",
            "7baf7bf0c9e745f28f1807d900374f1f",
            "91365f0f2e1c4bbf82ceffd6c8563463",
            "8bad28276687459394f9c42e884cc2f6",
            "8748e1bb1c524f8b9b53128502373141",
            "44bbd58e433c4767ba99fd7883723db3",
            "a345c6cad74d424e8100660c4d612adb",
            "25db1f1367f14b7089520168baf93d81",
            "f710a8aea9a742669000c84e9ca855c6",
            "b14c69dac3224b5186da559c32e2a4c3",
            "f5010e21d8ae4c7ab4a697cb20567814",
            "0c5cb64d3a364646b9be6be4d3996de4",
            "deff69f90ed448c19158442a5ab3845e",
            "ead56e3dd5004cca9eb83a85992ced1f",
            "65c5be703cf1494895d1a0824c04d587",
            "5eb747205781477dbf780a3b51f2374f"
          ]
        },
        "id": "zAo0YLB5-8zN",
        "outputId": "da93b6ed-ba54-4a37-ce32-26399d0532d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "221d3c411f3243febfad59c3f9423a11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/409 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d50a0b6bf78409c917b0317118a7f01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing aspect: Usability\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/62.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44bbd58e433c4767ba99fd7883723db3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6243\n",
            "Epoch 2/5, Loss: 0.5729\n",
            "Epoch 3/5, Loss: 0.5205\n",
            "Epoch 4/5, Loss: 0.4701\n",
            "Epoch 5/5, Loss: 0.4122\n",
            "Aspect: Usability\n",
            "Accuracy: 0.6017\n",
            "F1 Score (Micro): 0.6017\n",
            "F1 Score (Macro): 0.5947\n",
            "F1 Score (Weighted): 0.6134\n",
            "Total Inference Time: 0.343604 seconds\n",
            "Total Samples: 575\n",
            "Average Inference Time per Sample: 0.000598 seconds\n",
            "\n",
            "Processing aspect: Performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6801\n",
            "Epoch 2/5, Loss: 0.6692\n",
            "Epoch 3/5, Loss: 0.6508\n",
            "Epoch 4/5, Loss: 0.5481\n",
            "Epoch 5/5, Loss: 0.5618\n",
            "Aspect: Performance\n",
            "Accuracy: 0.5143\n",
            "F1 Score (Micro): 0.5143\n",
            "F1 Score (Macro): 0.5134\n",
            "F1 Score (Weighted): 0.5194\n",
            "Total Inference Time: 0.082561 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.000590 seconds\n",
            "\n",
            "Processing aspect: Bug\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.5981\n",
            "Epoch 2/5, Loss: 0.4572\n",
            "Epoch 3/5, Loss: 0.4232\n",
            "Epoch 4/5, Loss: 0.4258\n",
            "Epoch 5/5, Loss: 0.5301\n",
            "Aspect: Bug\n",
            "Accuracy: 0.8289\n",
            "F1 Score (Micro): 0.8289\n",
            "F1 Score (Macro): 0.4532\n",
            "F1 Score (Weighted): 0.7514\n",
            "Total Inference Time: 0.046852 seconds\n",
            "Total Samples: 76\n",
            "Average Inference Time per Sample: 0.000616 seconds\n",
            "\n",
            "Processing aspect: Security\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6009\n",
            "Epoch 2/5, Loss: 0.5610\n",
            "Epoch 3/5, Loss: 0.4562\n",
            "Epoch 4/5, Loss: 0.4483\n",
            "Epoch 5/5, Loss: 0.4472\n",
            "Aspect: Security\n",
            "Accuracy: 0.8182\n",
            "F1 Score (Micro): 0.8182\n",
            "F1 Score (Macro): 0.4500\n",
            "F1 Score (Weighted): 0.7364\n",
            "Total Inference Time: 0.043205 seconds\n",
            "Total Samples: 66\n",
            "Average Inference Time per Sample: 0.000655 seconds\n",
            "\n",
            "Processing aspect: Community\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6620\n",
            "Epoch 2/5, Loss: 0.6162\n",
            "Epoch 3/5, Loss: 0.5731\n",
            "Epoch 4/5, Loss: 0.5460\n",
            "Epoch 5/5, Loss: 0.5125\n",
            "Aspect: Community\n",
            "Accuracy: 0.6842\n",
            "F1 Score (Micro): 0.6842\n",
            "F1 Score (Macro): 0.4747\n",
            "F1 Score (Weighted): 0.5794\n",
            "Total Inference Time: 0.022970 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.000604 seconds\n",
            "\n",
            "Processing aspect: Compatibility\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6907\n",
            "Epoch 2/5, Loss: 0.6842\n",
            "Epoch 3/5, Loss: 0.6683\n",
            "Epoch 4/5, Loss: 0.6433\n",
            "Epoch 5/5, Loss: 0.5664\n",
            "Aspect: Compatibility\n",
            "Accuracy: 0.7105\n",
            "F1 Score (Micro): 0.7105\n",
            "F1 Score (Macro): 0.6140\n",
            "F1 Score (Weighted): 0.6851\n",
            "Total Inference Time: 0.044570 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.001173 seconds\n",
            "\n",
            "Processing aspect: Documentation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6293\n",
            "Epoch 2/5, Loss: 0.5943\n",
            "Epoch 3/5, Loss: 0.5747\n",
            "Epoch 4/5, Loss: 0.5172\n",
            "Epoch 5/5, Loss: 0.4585\n",
            "Aspect: Documentation\n",
            "Accuracy: 0.6373\n",
            "F1 Score (Micro): 0.6373\n",
            "F1 Score (Macro): 0.5163\n",
            "F1 Score (Weighted): 0.6112\n",
            "Total Inference Time: 0.038737 seconds\n",
            "Total Samples: 102\n",
            "Average Inference Time per Sample: 0.000380 seconds\n",
            "\n",
            "Processing aspect: Legal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6841\n",
            "Epoch 2/5, Loss: 0.6476\n",
            "Epoch 3/5, Loss: 0.6304\n",
            "Epoch 4/5, Loss: 0.6122\n",
            "Epoch 5/5, Loss: 0.6051\n",
            "Aspect: Legal\n",
            "Accuracy: 0.5500\n",
            "F1 Score (Micro): 0.5500\n",
            "F1 Score (Macro): 0.3548\n",
            "F1 Score (Weighted): 0.3903\n",
            "Total Inference Time: 0.008961 seconds\n",
            "Total Samples: 20\n",
            "Average Inference Time per Sample: 0.000448 seconds\n",
            "\n",
            "Processing aspect: Portability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6797\n",
            "Epoch 2/5, Loss: 0.6598\n",
            "Epoch 3/5, Loss: 0.5976\n",
            "Epoch 4/5, Loss: 0.6162\n",
            "Epoch 5/5, Loss: 0.6088\n",
            "Aspect: Portability\n",
            "Accuracy: 0.7143\n",
            "F1 Score (Micro): 0.7143\n",
            "F1 Score (Macro): 0.4167\n",
            "F1 Score (Weighted): 0.5952\n",
            "Total Inference Time: 0.014820 seconds\n",
            "Total Samples: 28\n",
            "Average Inference Time per Sample: 0.000529 seconds\n",
            "\n",
            "Processing aspect: OnlySentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6759\n",
            "Epoch 2/5, Loss: 0.6527\n",
            "Epoch 3/5, Loss: 0.6204\n",
            "Epoch 4/5, Loss: 0.5656\n",
            "Epoch 5/5, Loss: 0.4348\n",
            "Aspect: OnlySentiment\n",
            "Accuracy: 0.6929\n",
            "F1 Score (Micro): 0.6929\n",
            "F1 Score (Macro): 0.6500\n",
            "F1 Score (Weighted): 0.6762\n",
            "Total Inference Time: 0.058072 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.000415 seconds\n",
            "\n",
            "Processing aspect: Others\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.3665\n",
            "Epoch 2/5, Loss: 0.3306\n",
            "Epoch 3/5, Loss: 0.3285\n",
            "Epoch 4/5, Loss: 0.3308\n",
            "Epoch 5/5, Loss: 0.3342\n",
            "Aspect: Others\n",
            "Accuracy: 0.8868\n",
            "F1 Score (Micro): 0.8868\n",
            "F1 Score (Macro): 0.4700\n",
            "F1 Score (Weighted): 0.8335\n",
            "Total Inference Time: 0.263631 seconds\n",
            "Total Samples: 680\n",
            "Average Inference Time per Sample: 0.000388 seconds\n",
            "\n",
            "Final Results:\n",
            "           aspect  accuracy  f1_micro  f1_macro  f1_weighted  \\\n",
            "0       Usability  0.601739  0.601739  0.594658     0.613386   \n",
            "1     Performance  0.514286  0.514286  0.513392     0.519350   \n",
            "2             Bug  0.828947  0.828947  0.453237     0.751420   \n",
            "3        Security  0.818182  0.818182  0.450000     0.736364   \n",
            "4       Community  0.684211  0.684211  0.474654     0.579432   \n",
            "5   Compatibility  0.710526  0.710526  0.614035     0.685134   \n",
            "6   Documentation  0.637255  0.637255  0.516340     0.611175   \n",
            "7           Legal  0.550000  0.550000  0.354839     0.390323   \n",
            "8     Portability  0.714286  0.714286  0.416667     0.595238   \n",
            "9   OnlySentiment  0.692857  0.692857  0.649980     0.676231   \n",
            "10         Others  0.886765  0.886765  0.469992     0.833545   \n",
            "\n",
            "    total_inference_time  total_samples  average_inference_time  \n",
            "0               0.343604            575                0.000598  \n",
            "1               0.082561            140                0.000590  \n",
            "2               0.046852             76                0.000616  \n",
            "3               0.043205             66                0.000655  \n",
            "4               0.022970             38                0.000604  \n",
            "5               0.044570             38                0.001173  \n",
            "6               0.038737            102                0.000380  \n",
            "7               0.008961             20                0.000448  \n",
            "8               0.014820             28                0.000529  \n",
            "9               0.058072            140                0.000415  \n",
            "10              0.263631            680                0.000388  \n",
            "\n",
            "Model Score: 0.7704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Roberta Base\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Define the list of aspects\n",
        "aspects = [\n",
        "    'Usability', 'Performance', 'Bug', 'Security', 'Community',\n",
        "    'Compatibility', 'Documentation', 'Legal', 'Portability',\n",
        "    'OnlySentiment', 'Others'\n",
        "]\n",
        "\n",
        "# Initialize the tokenizer (RoBERTa tokenizer)\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "# File path to your dataset (update this path)\n",
        "file_path = '/content/BenchmarkUddinSO-ConsoliatedAspectSentiment.xls'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(file_path)\n",
        "df = data[['sent', 'ManualLabel', 'codes']]\n",
        "\n",
        "# Initialize a list to collect results\n",
        "results = []\n",
        "\n",
        "# Loop over each aspect\n",
        "for aspect in aspects:\n",
        "    print(f\"\\nProcessing aspect: {aspect}\")\n",
        "    # Filter the dataset for the current aspect\n",
        "    df_filtered = df[df['codes'].str.contains(aspect, case=False, na=False)].copy()\n",
        "\n",
        "    # Check if the filtered dataset is empty\n",
        "    if df_filtered.empty:\n",
        "        print(f\"No data found for aspect: {aspect}\")\n",
        "        continue\n",
        "\n",
        "    # Map labels: 'p' to 1 and others to 0\n",
        "    df_filtered['ManualLabel'] = df_filtered['ManualLabel'].apply(lambda x: 1 if x == 'p' else 0)\n",
        "\n",
        "    # Split the dataset\n",
        "    train_df, test_df = train_test_split(df_filtered, test_size=0.4, random_state=42)\n",
        "\n",
        "    # Tokenize the text data\n",
        "    def tokenize_function(texts):\n",
        "        return tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "    train_texts = train_df['sent'].tolist()\n",
        "    train_labels = train_df['ManualLabel'].tolist()\n",
        "    test_texts = test_df['sent'].tolist()\n",
        "    test_labels = test_df['ManualLabel'].tolist()\n",
        "\n",
        "    train_encodings = tokenize_function(train_texts)\n",
        "    test_encodings = tokenize_function(test_texts)\n",
        "\n",
        "    # Create a custom dataset class\n",
        "    class SentimentDataset(Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = {key: val.clone().detach() for key, val in encodings.items()}\n",
        "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx]\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = SentimentDataset(train_encodings, train_labels)\n",
        "    test_dataset = SentimentDataset(test_encodings, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # Initialize the RoBERTa model for sequence classification\n",
        "    model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    num_epochs = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    total_inference_time = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            total_inference_time += inference_time\n",
        "            total_samples += input_ids.size(0)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1_micro = f1_score(true_labels, predictions, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    average_inference_time = total_inference_time / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    # Print results\n",
        "    print(f'Aspect: {aspect}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'F1 Score (Micro): {f1_micro:.4f}')\n",
        "    print(f'F1 Score (Macro): {f1_macro:.4f}')\n",
        "    print(f'F1 Score (Weighted): {f1_weighted:.4f}')\n",
        "    print(f'Total Inference Time: {total_inference_time:.6f} seconds')\n",
        "    print(f'Total Samples: {total_samples}')\n",
        "    print(f'Average Inference Time per Sample: {average_inference_time:.6f} seconds')\n",
        "\n",
        "    # Collect results\n",
        "    results.append({\n",
        "        'aspect': aspect,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'total_inference_time': total_inference_time,\n",
        "        'total_samples': total_samples,\n",
        "        'average_inference_time': average_inference_time\n",
        "    })\n",
        "\n",
        "# After processing all aspects, display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# --- Model Score Calculation --- #\n",
        "\n",
        "# Compute Average F1 Score (avg. F1)\n",
        "avg_f1 = results_df['f1_micro'].mean()\n",
        "\n",
        "# Compute Measured Average Runtime (measured avg runtime)\n",
        "measured_avg_runtime = results_df['average_inference_time'].mean()\n",
        "\n",
        "# Compute Maximum Average Runtime (max avg runtime)\n",
        "max_avg_runtime = results_df['total_inference_time'].max()\n",
        "\n",
        "# Compute the Model Score\n",
        "model_score = (avg_f1) * 0.75 + ((max_avg_runtime - measured_avg_runtime) / max_avg_runtime) * 0.25\n",
        "\n",
        "print(f\"\\nModel Score: {model_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdNNdCP-_FDj",
        "outputId": "f2524b5e-1000-4c67-bcf5-1be8b9708416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing aspect: Usability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6419\n",
            "Epoch 2/5, Loss: 0.6237\n",
            "Epoch 3/5, Loss: 0.6329\n",
            "Epoch 4/5, Loss: 0.6291\n",
            "Epoch 5/5, Loss: 0.6265\n",
            "Aspect: Usability\n",
            "Accuracy: 0.6748\n",
            "F1 Score (Micro): 0.6748\n",
            "F1 Score (Macro): 0.4029\n",
            "F1 Score (Weighted): 0.5438\n",
            "Total Inference Time: 0.755263 seconds\n",
            "Total Samples: 575\n",
            "Average Inference Time per Sample: 0.001314 seconds\n",
            "\n",
            "Processing aspect: Performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6888\n",
            "Epoch 2/5, Loss: 0.6752\n",
            "Epoch 3/5, Loss: 0.6795\n",
            "Epoch 4/5, Loss: 0.6827\n",
            "Epoch 5/5, Loss: 0.6520\n",
            "Aspect: Performance\n",
            "Accuracy: 0.6429\n",
            "F1 Score (Micro): 0.6429\n",
            "F1 Score (Macro): 0.3913\n",
            "F1 Score (Weighted): 0.5031\n",
            "Total Inference Time: 0.195895 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.001399 seconds\n",
            "\n",
            "Processing aspect: Bug\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.5177\n",
            "Epoch 2/5, Loss: 0.5736\n",
            "Epoch 3/5, Loss: 0.4417\n",
            "Epoch 4/5, Loss: 0.4487\n",
            "Epoch 5/5, Loss: 0.4094\n",
            "Aspect: Bug\n",
            "Accuracy: 0.8289\n",
            "F1 Score (Micro): 0.8289\n",
            "F1 Score (Macro): 0.4532\n",
            "F1 Score (Weighted): 0.7514\n",
            "Total Inference Time: 0.154245 seconds\n",
            "Total Samples: 76\n",
            "Average Inference Time per Sample: 0.002030 seconds\n",
            "\n",
            "Processing aspect: Security\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.5378\n",
            "Epoch 2/5, Loss: 0.4698\n",
            "Epoch 3/5, Loss: 0.4457\n",
            "Epoch 4/5, Loss: 0.4220\n",
            "Epoch 5/5, Loss: 0.3392\n",
            "Aspect: Security\n",
            "Accuracy: 0.8182\n",
            "F1 Score (Micro): 0.8182\n",
            "F1 Score (Macro): 0.4500\n",
            "F1 Score (Weighted): 0.7364\n",
            "Total Inference Time: 0.123399 seconds\n",
            "Total Samples: 66\n",
            "Average Inference Time per Sample: 0.001870 seconds\n",
            "\n",
            "Processing aspect: Community\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6534\n",
            "Epoch 2/5, Loss: 0.5565\n",
            "Epoch 3/5, Loss: 0.5312\n",
            "Epoch 4/5, Loss: 0.5110\n",
            "Epoch 5/5, Loss: 0.2851\n",
            "Aspect: Community\n",
            "Accuracy: 0.6579\n",
            "F1 Score (Micro): 0.6579\n",
            "F1 Score (Macro): 0.4601\n",
            "F1 Score (Weighted): 0.5633\n",
            "Total Inference Time: 0.055398 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.001458 seconds\n",
            "\n",
            "Processing aspect: Compatibility\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.7164\n",
            "Epoch 2/5, Loss: 0.6856\n",
            "Epoch 3/5, Loss: 0.6771\n",
            "Epoch 4/5, Loss: 0.6454\n",
            "Epoch 5/5, Loss: 0.5506\n",
            "Aspect: Compatibility\n",
            "Accuracy: 0.5526\n",
            "F1 Score (Micro): 0.5526\n",
            "F1 Score (Macro): 0.5369\n",
            "F1 Score (Weighted): 0.5683\n",
            "Total Inference Time: 0.053740 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.001414 seconds\n",
            "\n",
            "Processing aspect: Documentation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6305\n",
            "Epoch 2/5, Loss: 0.5953\n",
            "Epoch 3/5, Loss: 0.5996\n",
            "Epoch 4/5, Loss: 0.5892\n",
            "Epoch 5/5, Loss: 0.5520\n",
            "Aspect: Documentation\n",
            "Accuracy: 0.5686\n",
            "F1 Score (Micro): 0.5686\n",
            "F1 Score (Macro): 0.5476\n",
            "F1 Score (Weighted): 0.5858\n",
            "Total Inference Time: 0.138121 seconds\n",
            "Total Samples: 102\n",
            "Average Inference Time per Sample: 0.001354 seconds\n",
            "\n",
            "Processing aspect: Legal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6139\n",
            "Epoch 2/5, Loss: 0.6061\n",
            "Epoch 3/5, Loss: 0.5800\n",
            "Epoch 4/5, Loss: 0.5268\n",
            "Epoch 5/5, Loss: 0.3499\n",
            "Aspect: Legal\n",
            "Accuracy: 0.5000\n",
            "F1 Score (Micro): 0.5000\n",
            "F1 Score (Macro): 0.3333\n",
            "F1 Score (Weighted): 0.3667\n",
            "Total Inference Time: 0.031758 seconds\n",
            "Total Samples: 20\n",
            "Average Inference Time per Sample: 0.001588 seconds\n",
            "\n",
            "Processing aspect: Portability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6425\n",
            "Epoch 2/5, Loss: 0.6594\n",
            "Epoch 3/5, Loss: 0.6114\n",
            "Epoch 4/5, Loss: 0.5812\n",
            "Epoch 5/5, Loss: 0.5553\n",
            "Aspect: Portability\n",
            "Accuracy: 0.7143\n",
            "F1 Score (Micro): 0.7143\n",
            "F1 Score (Macro): 0.4167\n",
            "F1 Score (Weighted): 0.5952\n",
            "Total Inference Time: 0.044506 seconds\n",
            "Total Samples: 28\n",
            "Average Inference Time per Sample: 0.001589 seconds\n",
            "\n",
            "Processing aspect: OnlySentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6822\n",
            "Epoch 2/5, Loss: 0.6838\n",
            "Epoch 3/5, Loss: 0.6812\n",
            "Epoch 4/5, Loss: 0.6715\n",
            "Epoch 5/5, Loss: 0.6858\n",
            "Aspect: OnlySentiment\n",
            "Accuracy: 0.6071\n",
            "F1 Score (Micro): 0.6071\n",
            "F1 Score (Macro): 0.3778\n",
            "F1 Score (Weighted): 0.4587\n",
            "Total Inference Time: 0.209421 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.001496 seconds\n",
            "\n",
            "Processing aspect: Others\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.3687\n",
            "Epoch 2/5, Loss: 0.3450\n",
            "Epoch 3/5, Loss: 0.3379\n",
            "Epoch 4/5, Loss: 0.3346\n",
            "Epoch 5/5, Loss: 0.3346\n",
            "Aspect: Others\n",
            "Accuracy: 0.8868\n",
            "F1 Score (Micro): 0.8868\n",
            "F1 Score (Macro): 0.4700\n",
            "F1 Score (Weighted): 0.8335\n",
            "Total Inference Time: 2.349885 seconds\n",
            "Total Samples: 680\n",
            "Average Inference Time per Sample: 0.003456 seconds\n",
            "\n",
            "Final Results:\n",
            "           aspect  accuracy  f1_micro  f1_macro  f1_weighted  \\\n",
            "0       Usability  0.674783  0.674783  0.402908     0.543750   \n",
            "1     Performance  0.642857  0.642857  0.391304     0.503106   \n",
            "2             Bug  0.828947  0.828947  0.453237     0.751420   \n",
            "3        Security  0.818182  0.818182  0.450000     0.736364   \n",
            "4       Community  0.657895  0.657895  0.460109     0.563302   \n",
            "5   Compatibility  0.552632  0.552632  0.536918     0.568346   \n",
            "6   Documentation  0.568627  0.568627  0.547581     0.585848   \n",
            "7           Legal  0.500000  0.500000  0.333333     0.366667   \n",
            "8     Portability  0.714286  0.714286  0.416667     0.595238   \n",
            "9   OnlySentiment  0.607143  0.607143  0.377778     0.458730   \n",
            "10         Others  0.886765  0.886765  0.469992     0.833545   \n",
            "\n",
            "    total_inference_time  total_samples  average_inference_time  \n",
            "0               0.755263            575                0.001314  \n",
            "1               0.195895            140                0.001399  \n",
            "2               0.154245             76                0.002030  \n",
            "3               0.123399             66                0.001870  \n",
            "4               0.055398             38                0.001458  \n",
            "5               0.053740             38                0.001414  \n",
            "6               0.138121            102                0.001354  \n",
            "7               0.031758             20                0.001588  \n",
            "8               0.044506             28                0.001589  \n",
            "9               0.209421            140                0.001496  \n",
            "10              2.349885            680                0.003456  \n",
            "\n",
            "Model Score: 0.7579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distill Bert Revised\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Define the list of aspects\n",
        "aspects = [\n",
        "    'Usability', 'Performance', 'Bug', 'Security', 'Community',\n",
        "    'Compatibility', 'Documentation', 'Legal', 'Portability',\n",
        "    'OnlySentiment', 'Others'\n",
        "]\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# File path to your dataset (update this path)\n",
        "file_path = '/content/BenchmarkUddinSO-ConsoliatedAspectSentiment.xls'  # Update this path\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(file_path)\n",
        "df = data[['sent', 'ManualLabel', 'codes']]\n",
        "\n",
        "# Initialize a list to collect results\n",
        "results = []\n",
        "\n",
        "# Loop over each aspect\n",
        "for aspect in aspects:\n",
        "    print(f\"\\nProcessing aspect: {aspect}\")\n",
        "    # Filter the dataset for the current aspect\n",
        "    df_filtered = df[df['codes'].str.contains(aspect, case=False, na=False)].copy()\n",
        "\n",
        "    # Check if the filtered dataset is empty\n",
        "    if df_filtered.empty:\n",
        "        print(f\"No data found for aspect: {aspect}\")\n",
        "        continue\n",
        "\n",
        "    # Map labels: 'p' to 1 and others to 0\n",
        "    df_filtered['ManualLabel'] = df_filtered['ManualLabel'].apply(lambda x: 1 if x == 'p' else 0)\n",
        "\n",
        "    # Split the dataset\n",
        "    train_df, test_df = train_test_split(df_filtered, test_size=0.4, random_state=42)\n",
        "\n",
        "    # Tokenize the text data\n",
        "    def tokenize_function(texts):\n",
        "        return tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "    train_texts = train_df['sent'].tolist()\n",
        "    train_labels = train_df['ManualLabel'].tolist()\n",
        "    test_texts = test_df['sent'].tolist()\n",
        "    test_labels = test_df['ManualLabel'].tolist()\n",
        "\n",
        "    train_encodings = tokenize_function(train_texts)\n",
        "    test_encodings = tokenize_function(test_texts)\n",
        "\n",
        "    # Create a custom dataset class\n",
        "    class SentimentDataset(Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx]\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = SentimentDataset(train_encodings, train_labels)\n",
        "    test_dataset = SentimentDataset(test_encodings, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # Initialize the model and optimizer\n",
        "    num_labels = 2\n",
        "    model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    num_epochs = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    total_inference_time = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            logits = outputs.logits\n",
        "            preds = logits.argmax(dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            total_inference_time += inference_time\n",
        "            total_samples += input_ids.size(0)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1_micro = f1_score(true_labels, predictions, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    average_inference_time = total_inference_time / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    # Print results\n",
        "    print(f'Aspect: {aspect}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'F1 Score (Micro): {f1_micro:.4f}')\n",
        "    print(f'F1 Score (Macro): {f1_macro:.4f}')\n",
        "    print(f'F1 Score (Weighted): {f1_weighted:.4f}')\n",
        "    print(f'Total Inference Time: {total_inference_time:.6f} seconds')\n",
        "    print(f'Total Samples: {total_samples}')\n",
        "    print(f'Average Inference Time per Sample: {average_inference_time:.6f} seconds')\n",
        "\n",
        "    # Collect results\n",
        "    results.append({\n",
        "        'aspect': aspect,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'total_inference_time': total_inference_time,\n",
        "        'total_samples': total_samples,\n",
        "        'average_inference_time': average_inference_time\n",
        "    })\n",
        "\n",
        "# After processing all aspects, display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# --- Model Score Calculation --- #\n",
        "\n",
        "# Compute Average F1 Score (avg. F1)\n",
        "avg_f1 = results_df['f1_micro'].mean()\n",
        "\n",
        "# Compute Measured Average Runtime (measured avg runtime)\n",
        "measured_avg_runtime = results_df['average_inference_time'].mean()\n",
        "\n",
        "# Compute Maximum Average Runtime (max avg runtime)\n",
        "max_avg_runtime = results_df['total_inference_time'].max()\n",
        "\n",
        "# Compute the Model Score\n",
        "model_score = (avg_f1) * 0.75 + ((max_avg_runtime - measured_avg_runtime) / max_avg_runtime) * 0.25\n",
        "\n",
        "print(f\"\\nModel Score: {model_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr88kCZ7GphB",
        "outputId": "edd74beb-cce8-4f8e-e217-a55b05f55692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing aspect: Usability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6074\n",
            "Epoch 2/5, Loss: 0.4859\n",
            "Epoch 3/5, Loss: 0.2657\n",
            "Epoch 4/5, Loss: 0.1184\n",
            "Epoch 5/5, Loss: 0.0752\n",
            "Aspect: Usability\n",
            "Accuracy: 0.6817\n",
            "F1 Score (Micro): 0.6817\n",
            "F1 Score (Macro): 0.6445\n",
            "F1 Score (Weighted): 0.6847\n",
            "Total Inference Time: 0.438476 seconds\n",
            "Total Samples: 575\n",
            "Average Inference Time per Sample: 0.000763 seconds\n",
            "\n",
            "Processing aspect: Performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6868\n",
            "Epoch 2/5, Loss: 0.6685\n",
            "Epoch 3/5, Loss: 0.6272\n",
            "Epoch 4/5, Loss: 0.4051\n",
            "Epoch 5/5, Loss: 0.1681\n",
            "Aspect: Performance\n",
            "Accuracy: 0.6357\n",
            "F1 Score (Micro): 0.6357\n",
            "F1 Score (Macro): 0.6015\n",
            "F1 Score (Weighted): 0.6349\n",
            "Total Inference Time: 0.106564 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.000761 seconds\n",
            "\n",
            "Processing aspect: Bug\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.4883\n",
            "Epoch 2/5, Loss: 0.4041\n",
            "Epoch 3/5, Loss: 0.3638\n",
            "Epoch 4/5, Loss: 0.1812\n",
            "Epoch 5/5, Loss: 0.0915\n",
            "Aspect: Bug\n",
            "Accuracy: 0.7500\n",
            "F1 Score (Micro): 0.7500\n",
            "F1 Score (Macro): 0.5952\n",
            "F1 Score (Weighted): 0.7599\n",
            "Total Inference Time: 0.066012 seconds\n",
            "Total Samples: 76\n",
            "Average Inference Time per Sample: 0.000869 seconds\n",
            "\n",
            "Processing aspect: Security\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.5391\n",
            "Epoch 2/5, Loss: 0.5687\n",
            "Epoch 3/5, Loss: 0.4639\n",
            "Epoch 4/5, Loss: 0.4250\n",
            "Epoch 5/5, Loss: 0.4299\n",
            "Aspect: Security\n",
            "Accuracy: 0.8182\n",
            "F1 Score (Micro): 0.8182\n",
            "F1 Score (Macro): 0.4500\n",
            "F1 Score (Weighted): 0.7364\n",
            "Total Inference Time: 0.087425 seconds\n",
            "Total Samples: 66\n",
            "Average Inference Time per Sample: 0.001325 seconds\n",
            "\n",
            "Processing aspect: Community\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6131\n",
            "Epoch 2/5, Loss: 0.5328\n",
            "Epoch 3/5, Loss: 0.3902\n",
            "Epoch 4/5, Loss: 0.2240\n",
            "Epoch 5/5, Loss: 0.0637\n",
            "Aspect: Community\n",
            "Accuracy: 0.6316\n",
            "F1 Score (Micro): 0.6316\n",
            "F1 Score (Macro): 0.3871\n",
            "F1 Score (Weighted): 0.5093\n",
            "Total Inference Time: 0.033148 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.000872 seconds\n",
            "\n",
            "Processing aspect: Compatibility\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.7169\n",
            "Epoch 2/5, Loss: 0.6667\n",
            "Epoch 3/5, Loss: 0.6253\n",
            "Epoch 4/5, Loss: 0.4948\n",
            "Epoch 5/5, Loss: 0.2248\n",
            "Aspect: Compatibility\n",
            "Accuracy: 0.7105\n",
            "F1 Score (Micro): 0.7105\n",
            "F1 Score (Macro): 0.6140\n",
            "F1 Score (Weighted): 0.6851\n",
            "Total Inference Time: 0.028947 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.000762 seconds\n",
            "\n",
            "Processing aspect: Documentation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6138\n",
            "Epoch 2/5, Loss: 0.4977\n",
            "Epoch 3/5, Loss: 0.3266\n",
            "Epoch 4/5, Loss: 0.1918\n",
            "Epoch 5/5, Loss: 0.0497\n",
            "Aspect: Documentation\n",
            "Accuracy: 0.6961\n",
            "F1 Score (Micro): 0.6961\n",
            "F1 Score (Macro): 0.5837\n",
            "F1 Score (Weighted): 0.6685\n",
            "Total Inference Time: 0.079418 seconds\n",
            "Total Samples: 102\n",
            "Average Inference Time per Sample: 0.000779 seconds\n",
            "\n",
            "Processing aspect: Legal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6536\n",
            "Epoch 2/5, Loss: 0.5440\n",
            "Epoch 3/5, Loss: 0.4912\n",
            "Epoch 4/5, Loss: 0.3582\n",
            "Epoch 5/5, Loss: 0.2608\n",
            "Aspect: Legal\n",
            "Accuracy: 0.7500\n",
            "F1 Score (Micro): 0.7500\n",
            "F1 Score (Macro): 0.7333\n",
            "F1 Score (Weighted): 0.7400\n",
            "Total Inference Time: 0.017603 seconds\n",
            "Total Samples: 20\n",
            "Average Inference Time per Sample: 0.000880 seconds\n",
            "\n",
            "Processing aspect: Portability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6690\n",
            "Epoch 2/5, Loss: 0.5870\n",
            "Epoch 3/5, Loss: 0.4963\n",
            "Epoch 4/5, Loss: 0.4135\n",
            "Epoch 5/5, Loss: 0.2499\n",
            "Aspect: Portability\n",
            "Accuracy: 0.7143\n",
            "F1 Score (Micro): 0.7143\n",
            "F1 Score (Macro): 0.5758\n",
            "F1 Score (Weighted): 0.6797\n",
            "Total Inference Time: 0.038813 seconds\n",
            "Total Samples: 28\n",
            "Average Inference Time per Sample: 0.001386 seconds\n",
            "\n",
            "Processing aspect: OnlySentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6853\n",
            "Epoch 2/5, Loss: 0.6203\n",
            "Epoch 3/5, Loss: 0.4609\n",
            "Epoch 4/5, Loss: 0.2601\n",
            "Epoch 5/5, Loss: 0.1276\n",
            "Aspect: OnlySentiment\n",
            "Accuracy: 0.6714\n",
            "F1 Score (Micro): 0.6714\n",
            "F1 Score (Macro): 0.6453\n",
            "F1 Score (Weighted): 0.6659\n",
            "Total Inference Time: 0.132648 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.000947 seconds\n",
            "\n",
            "Processing aspect: Others\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.3461\n",
            "Epoch 2/5, Loss: 0.3281\n",
            "Epoch 3/5, Loss: 0.3164\n",
            "Epoch 4/5, Loss: 0.2846\n",
            "Epoch 5/5, Loss: 0.1792\n",
            "Aspect: Others\n",
            "Accuracy: 0.8647\n",
            "F1 Score (Micro): 0.8647\n",
            "F1 Score (Macro): 0.5125\n",
            "F1 Score (Weighted): 0.8330\n",
            "Total Inference Time: 0.561603 seconds\n",
            "Total Samples: 680\n",
            "Average Inference Time per Sample: 0.000826 seconds\n",
            "\n",
            "Final Results:\n",
            "           aspect  accuracy  f1_micro  f1_macro  f1_weighted  \\\n",
            "0       Usability  0.681739  0.681739  0.644545     0.684739   \n",
            "1     Performance  0.635714  0.635714  0.601540     0.634881   \n",
            "2             Bug  0.750000  0.750000  0.595178     0.759882   \n",
            "3        Security  0.818182  0.818182  0.450000     0.736364   \n",
            "4       Community  0.631579  0.631579  0.387097     0.509338   \n",
            "5   Compatibility  0.710526  0.710526  0.614035     0.685134   \n",
            "6   Documentation  0.696078  0.696078  0.583673     0.668507   \n",
            "7           Legal  0.750000  0.750000  0.733333     0.740000   \n",
            "8     Portability  0.714286  0.714286  0.575758     0.679654   \n",
            "9   OnlySentiment  0.671429  0.671429  0.645296     0.665927   \n",
            "10         Others  0.864706  0.864706  0.512454     0.833015   \n",
            "\n",
            "    total_inference_time  total_samples  average_inference_time  \n",
            "0               0.438476            575                0.000763  \n",
            "1               0.106564            140                0.000761  \n",
            "2               0.066012             76                0.000869  \n",
            "3               0.087425             66                0.001325  \n",
            "4               0.033148             38                0.000872  \n",
            "5               0.028947             38                0.000762  \n",
            "6               0.079418            102                0.000779  \n",
            "7               0.017603             20                0.000880  \n",
            "8               0.038813             28                0.001386  \n",
            "9               0.132648            140                0.000947  \n",
            "10              0.561603            680                0.000826  \n",
            "\n",
            "Model Score: 0.7899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Roberta Large\n",
        "# !pip install pandas numpy scikit-learn torch torchvision torchaudio transformers\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Define the list of aspects\n",
        "aspects = [\n",
        "    'Usability', 'Performance', 'Bug', 'Security', 'Community',\n",
        "    'Compatibility', 'Documentation', 'Legal', 'Portability',\n",
        "    'OnlySentiment', 'Others'\n",
        "]\n",
        "\n",
        "# Initialize the tokenizer (RoBERTa-large tokenizer)\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "# File path to your dataset (update this path)\n",
        "file_path = '/content/BenchmarkUddinSO-ConsoliatedAspectSentiment.xls'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel(file_path)\n",
        "df = data[['sent', 'ManualLabel', 'codes']]\n",
        "\n",
        "# Initialize a list to collect results\n",
        "results = []\n",
        "\n",
        "# Loop over each aspect\n",
        "for aspect in aspects:\n",
        "    print(f\"\\nProcessing aspect: {aspect}\")\n",
        "    # Filter the dataset for the current aspect\n",
        "    df_filtered = df[df['codes'].str.contains(aspect, case=False, na=False)].copy()\n",
        "\n",
        "    # Check if the filtered dataset is empty\n",
        "    if df_filtered.empty:\n",
        "        print(f\"No data found for aspect: {aspect}\")\n",
        "        continue\n",
        "\n",
        "    # Map labels: 'p' to 1 and others to 0\n",
        "    df_filtered['ManualLabel'] = df_filtered['ManualLabel'].apply(lambda x: 1 if x == 'p' else 0)\n",
        "\n",
        "    # Split the dataset\n",
        "    train_df, test_df = train_test_split(df_filtered, test_size=0.4, random_state=42)\n",
        "\n",
        "    # Tokenize the text data\n",
        "    def tokenize_function(texts):\n",
        "        return tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "    train_texts = train_df['sent'].tolist()\n",
        "    train_labels = train_df['ManualLabel'].tolist()\n",
        "    test_texts = test_df['sent'].tolist()\n",
        "    test_labels = test_df['ManualLabel'].tolist()\n",
        "\n",
        "    train_encodings = tokenize_function(train_texts)\n",
        "    test_encodings = tokenize_function(test_texts)\n",
        "\n",
        "    # Create a custom dataset class\n",
        "    class SentimentDataset(Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = {key: val.clone().detach() for key, val in encodings.items()}\n",
        "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "            item['labels'] = self.labels[idx]\n",
        "            return item\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = SentimentDataset(train_encodings, train_labels)\n",
        "    test_dataset = SentimentDataset(test_encodings, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "    # Initialize the RoBERTa-large model for sequence classification\n",
        "    model = RobertaForSequenceClassification.from_pretrained('roberta-large', num_labels=2)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    num_epochs = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    total_inference_time = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            inference_time = time.time() - start_time\n",
        "\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            total_inference_time += inference_time\n",
        "            total_samples += input_ids.size(0)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1_micro = f1_score(true_labels, predictions, average='micro', zero_division=0)\n",
        "    f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
        "\n",
        "    average_inference_time = total_inference_time / total_samples if total_samples > 0 else 0\n",
        "\n",
        "    # Print results\n",
        "    print(f'Aspect: {aspect}')\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'F1 Score (Micro): {f1_micro:.4f}')\n",
        "    print(f'F1 Score (Macro): {f1_macro:.4f}')\n",
        "    print(f'F1 Score (Weighted): {f1_weighted:.4f}')\n",
        "    print(f'Total Inference Time: {total_inference_time:.6f} seconds')\n",
        "    print(f'Total Samples: {total_samples}')\n",
        "    print(f'Average Inference Time per Sample: {average_inference_time:.6f} seconds')\n",
        "\n",
        "    # Collect results\n",
        "    results.append({\n",
        "        'aspect': aspect,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_micro': f1_micro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'total_inference_time': total_inference_time,\n",
        "        'total_samples': total_samples,\n",
        "        'average_inference_time': average_inference_time\n",
        "    })\n",
        "\n",
        "# After processing all aspects, display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# --- Model Score Calculation --- #\n",
        "\n",
        "# Compute Average F1 Score (avg. F1)\n",
        "avg_f1 = results_df['f1_micro'].mean()\n",
        "\n",
        "# Compute Measured Average Runtime (measured avg runtime)\n",
        "measured_avg_runtime = results_df['average_inference_time'].mean()\n",
        "\n",
        "# Compute Maximum Average Runtime (max avg runtime)\n",
        "max_avg_runtime = results_df['total_inference_time'].max()\n",
        "\n",
        "# Compute the Model Score\n",
        "model_score = (avg_f1) * 0.75 + ((max_avg_runtime - measured_avg_runtime) / max_avg_runtime) * 0.25\n",
        "\n",
        "print(f\"\\nModel Score: {model_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a8cb2d586284ebe82d3ee6ee5a82626",
            "51c0a6b4e16c4ed7843640c66ec126ee",
            "66c823828586421faebab29ae48e22f8",
            "ad91860ea2754f77a9d7facec2079b4b",
            "9a35af8a013a497c85678d4fa5e79a3c",
            "c344cae90c004f29b87b1ae75969982b",
            "ceb338cfe4474a95941a868286354c7f",
            "c7536aad74534a54a5fd6240830fe595",
            "59fed2e517394c1eb5d697c75b83e193",
            "4e006879344a440da0fe8b70f3d8ed53",
            "7d6c547fed374fdc9c95a3bd6f699193",
            "b129832d2b8848dbb1299e5709dbf40a",
            "b2404ed4b6dd490580de79420e7b2a66",
            "231364ce4bab4c7bb6cb824983af2caa",
            "01767d020b23433fb982491dd49ecb00",
            "5d5c12b51513458cbb12f315760eabb1",
            "7897f868a2ac44c28ebfa2d8553b2e13",
            "be574c99ebb346d4b2f73568c0225a7b",
            "b3c63b807e81425fb48cbcef4afbf89c",
            "e2849510b6bc4bbda8110f59aa3e56f3",
            "c7796098294140e5a3fbd2d5661733ea",
            "3cb212392a884df8b1540e513a9fb2bc",
            "358a75d0732d403d9535f855f58f737d",
            "7822d87e846e42a0b4e3395f4de29e52",
            "032804685f6a47f4854bf938fa0148a3",
            "69fdc1eceda343209f893ba4cfdfa45c",
            "e7e6b7282eb44ab1a1aa06f8ed6cad43",
            "29b899f207434a649c32c83f870cef2b",
            "d2ff471a42604168ae1135d2bd948fac",
            "d00790f52153409287b644cd652f6cad",
            "27611a0011304f229493bb336437cb8d",
            "865d0b02bbb34186a8da13005dc6a03f",
            "04d614cff9f74e3a872cde20ea43b1b8",
            "49686b7deee24f6fa3306a354b669edf",
            "bdf0d9e67d22437c91e00739dac37716",
            "949543220b6841f29e92469a965eed7f",
            "f93dd733f64b4e4c99336fe83697cc9d",
            "f36cb60a34c34fad99bd758b7b3e50d4",
            "afb8733b5cc944e2bd0565c55d6f945e",
            "5946c4c546304987a44d36de36489965",
            "b9938292b03d434080814889e21bf50e",
            "0047eff84369450fae2b9e51d4470e39",
            "91da51ada0414a0bb493884cef0626fc",
            "253a98d1c08b4a1d93ff9f6f865978bf",
            "b04ac51ec0d24c33a833fdf017dd9fb6",
            "a0b692cc587a4d8aae358e5fdc232271",
            "1847ffc6a2884d91958fc863fe130cf8",
            "a35ac1ce1556491f8790f71e45295c47",
            "853ff37c402f4fb4bc902ba1c96fae13",
            "eafac7c5a9e24dd3b876ef0fd0a63d69",
            "45f93f2e44a741e29e8fcd38a1eb8c0c",
            "986588776d2d4502b02fb4c4e9b99f83",
            "eaa78cfcf2a94ea8aa119a50225c17b5",
            "367629cd71114f71821829cb2cfa31f0",
            "2cbf39a147774d60bd5d539fe093dd5b"
          ]
        },
        "id": "pC9Lq7-cLikv",
        "outputId": "8b3a4d6c-dccb-4c0d-c416-61ee8e4118fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a8cb2d586284ebe82d3ee6ee5a82626"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b129832d2b8848dbb1299e5709dbf40a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "358a75d0732d403d9535f855f58f737d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49686b7deee24f6fa3306a354b669edf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing aspect: Usability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b04ac51ec0d24c33a833fdf017dd9fb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6652\n",
            "Epoch 2/5, Loss: 0.6526\n",
            "Epoch 3/5, Loss: 0.6383\n",
            "Epoch 4/5, Loss: 0.6391\n",
            "Epoch 5/5, Loss: 0.6460\n",
            "Aspect: Usability\n",
            "Accuracy: 0.6748\n",
            "F1 Score (Micro): 0.6748\n",
            "F1 Score (Macro): 0.4029\n",
            "F1 Score (Weighted): 0.5438\n",
            "Total Inference Time: 1.722734 seconds\n",
            "Total Samples: 575\n",
            "Average Inference Time per Sample: 0.002996 seconds\n",
            "\n",
            "Processing aspect: Performance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6804\n",
            "Epoch 2/5, Loss: 0.6604\n",
            "Epoch 3/5, Loss: 0.6798\n",
            "Epoch 4/5, Loss: 0.6842\n",
            "Epoch 5/5, Loss: 0.6789\n",
            "Aspect: Performance\n",
            "Accuracy: 0.6429\n",
            "F1 Score (Micro): 0.6429\n",
            "F1 Score (Macro): 0.3913\n",
            "F1 Score (Weighted): 0.5031\n",
            "Total Inference Time: 0.425252 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.003038 seconds\n",
            "\n",
            "Processing aspect: Bug\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6781\n",
            "Epoch 2/5, Loss: 0.4800\n",
            "Epoch 3/5, Loss: 0.4208\n",
            "Epoch 4/5, Loss: 0.4460\n",
            "Epoch 5/5, Loss: 0.4628\n",
            "Aspect: Bug\n",
            "Accuracy: 0.8289\n",
            "F1 Score (Micro): 0.8289\n",
            "F1 Score (Macro): 0.4532\n",
            "F1 Score (Weighted): 0.7514\n",
            "Total Inference Time: 0.322428 seconds\n",
            "Total Samples: 76\n",
            "Average Inference Time per Sample: 0.004242 seconds\n",
            "\n",
            "Processing aspect: Security\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.4638\n",
            "Epoch 2/5, Loss: 0.5183\n",
            "Epoch 3/5, Loss: 0.4536\n",
            "Epoch 4/5, Loss: 0.4697\n",
            "Epoch 5/5, Loss: 0.4517\n",
            "Aspect: Security\n",
            "Accuracy: 0.8182\n",
            "F1 Score (Micro): 0.8182\n",
            "F1 Score (Macro): 0.4500\n",
            "F1 Score (Weighted): 0.7364\n",
            "Total Inference Time: 0.203732 seconds\n",
            "Total Samples: 66\n",
            "Average Inference Time per Sample: 0.003087 seconds\n",
            "\n",
            "Processing aspect: Community\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.7262\n",
            "Epoch 2/5, Loss: 0.5663\n",
            "Epoch 3/5, Loss: 0.5696\n",
            "Epoch 4/5, Loss: 0.6128\n",
            "Epoch 5/5, Loss: 0.5631\n",
            "Aspect: Community\n",
            "Accuracy: 0.6579\n",
            "F1 Score (Micro): 0.6579\n",
            "F1 Score (Macro): 0.3968\n",
            "F1 Score (Weighted): 0.5221\n",
            "Total Inference Time: 0.157927 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.004156 seconds\n",
            "\n",
            "Processing aspect: Compatibility\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.7882\n",
            "Epoch 2/5, Loss: 0.7111\n",
            "Epoch 3/5, Loss: 0.7100\n",
            "Epoch 4/5, Loss: 0.6963\n",
            "Epoch 5/5, Loss: 0.6895\n",
            "Aspect: Compatibility\n",
            "Accuracy: 0.6842\n",
            "F1 Score (Micro): 0.6842\n",
            "F1 Score (Macro): 0.4062\n",
            "F1 Score (Weighted): 0.5559\n",
            "Total Inference Time: 0.108717 seconds\n",
            "Total Samples: 38\n",
            "Average Inference Time per Sample: 0.002861 seconds\n",
            "\n",
            "Processing aspect: Documentation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6379\n",
            "Epoch 2/5, Loss: 0.6252\n",
            "Epoch 3/5, Loss: 0.5980\n",
            "Epoch 4/5, Loss: 0.6200\n",
            "Epoch 5/5, Loss: 0.6287\n",
            "Aspect: Documentation\n",
            "Accuracy: 0.6961\n",
            "F1 Score (Micro): 0.6961\n",
            "F1 Score (Macro): 0.4104\n",
            "F1 Score (Weighted): 0.5713\n",
            "Total Inference Time: 0.292930 seconds\n",
            "Total Samples: 102\n",
            "Average Inference Time per Sample: 0.002872 seconds\n",
            "\n",
            "Processing aspect: Legal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.7337\n",
            "Epoch 2/5, Loss: 0.7447\n",
            "Epoch 3/5, Loss: 0.6899\n",
            "Epoch 4/5, Loss: 0.5719\n",
            "Epoch 5/5, Loss: 0.5307\n",
            "Aspect: Legal\n",
            "Accuracy: 0.5500\n",
            "F1 Score (Micro): 0.5500\n",
            "F1 Score (Macro): 0.3548\n",
            "F1 Score (Weighted): 0.3903\n",
            "Total Inference Time: 0.067950 seconds\n",
            "Total Samples: 20\n",
            "Average Inference Time per Sample: 0.003397 seconds\n",
            "\n",
            "Processing aspect: Portability\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6269\n",
            "Epoch 2/5, Loss: 0.6225\n",
            "Epoch 3/5, Loss: 0.7693\n",
            "Epoch 4/5, Loss: 0.6974\n",
            "Epoch 5/5, Loss: 0.6253\n",
            "Aspect: Portability\n",
            "Accuracy: 0.7143\n",
            "F1 Score (Micro): 0.7143\n",
            "F1 Score (Macro): 0.4167\n",
            "F1 Score (Weighted): 0.5952\n",
            "Total Inference Time: 0.087677 seconds\n",
            "Total Samples: 28\n",
            "Average Inference Time per Sample: 0.003131 seconds\n",
            "\n",
            "Processing aspect: OnlySentiment\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.7132\n",
            "Epoch 2/5, Loss: 0.6961\n",
            "Epoch 3/5, Loss: 0.6837\n",
            "Epoch 4/5, Loss: 0.6866\n",
            "Epoch 5/5, Loss: 0.6664\n",
            "Aspect: OnlySentiment\n",
            "Accuracy: 0.6071\n",
            "F1 Score (Micro): 0.6071\n",
            "F1 Score (Macro): 0.3778\n",
            "F1 Score (Weighted): 0.4587\n",
            "Total Inference Time: 0.410434 seconds\n",
            "Total Samples: 140\n",
            "Average Inference Time per Sample: 0.002932 seconds\n",
            "\n",
            "Processing aspect: Others\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:371: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.3701\n",
            "Epoch 2/5, Loss: 0.3375\n",
            "Epoch 3/5, Loss: 0.3397\n",
            "Epoch 4/5, Loss: 0.3482\n",
            "Epoch 5/5, Loss: 0.3411\n",
            "Aspect: Others\n",
            "Accuracy: 0.8868\n",
            "F1 Score (Micro): 0.8868\n",
            "F1 Score (Macro): 0.4700\n",
            "F1 Score (Weighted): 0.8335\n",
            "Total Inference Time: 2.025745 seconds\n",
            "Total Samples: 680\n",
            "Average Inference Time per Sample: 0.002979 seconds\n",
            "\n",
            "Final Results:\n",
            "           aspect  accuracy  f1_micro  f1_macro  f1_weighted  \\\n",
            "0       Usability  0.674783  0.674783  0.402908     0.543750   \n",
            "1     Performance  0.642857  0.642857  0.391304     0.503106   \n",
            "2             Bug  0.828947  0.828947  0.453237     0.751420   \n",
            "3        Security  0.818182  0.818182  0.450000     0.736364   \n",
            "4       Community  0.657895  0.657895  0.396825     0.522139   \n",
            "5   Compatibility  0.684211  0.684211  0.406250     0.555921   \n",
            "6   Documentation  0.696078  0.696078  0.410405     0.571348   \n",
            "7           Legal  0.550000  0.550000  0.354839     0.390323   \n",
            "8     Portability  0.714286  0.714286  0.416667     0.595238   \n",
            "9   OnlySentiment  0.607143  0.607143  0.377778     0.458730   \n",
            "10         Others  0.886765  0.886765  0.469992     0.833545   \n",
            "\n",
            "    total_inference_time  total_samples  average_inference_time  \n",
            "0               1.722734            575                0.002996  \n",
            "1               0.425252            140                0.003038  \n",
            "2               0.322428             76                0.004242  \n",
            "3               0.203732             66                0.003087  \n",
            "4               0.157927             38                0.004156  \n",
            "5               0.108717             38                0.002861  \n",
            "6               0.292930            102                0.002872  \n",
            "7               0.067950             20                0.003397  \n",
            "8               0.087677             28                0.003131  \n",
            "9               0.410434            140                0.002932  \n",
            "10              2.025745            680                0.002979  \n",
            "\n",
            "Model Score: 0.7788\n"
          ]
        }
      ]
    }
  ]
}